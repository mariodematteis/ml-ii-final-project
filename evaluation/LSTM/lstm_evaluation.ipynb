{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_folder = Path(\"../../data\")\n",
    "\n",
    "prod_data_folder: Path = data_folder.joinpath(\"30_prod/\")\n",
    "model_artifact = Path(\"../../models/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (8, 6), \"text.usetex\": True})\n",
    "\n",
    "GENERATOR_KEYWORD: str = \"GENERATOR\"\n",
    "DISCRIMINATOR_KEYWORD: str = \"DISCRIMINATOR\"\n",
    "\n",
    "MODEL_TYPE: str = \"GAN_LSTM\"\n",
    "\n",
    "AAPL_TICKER: str = \"AAPL\"\n",
    "ACWI_TICKER: str = \"ACWI\"\n",
    "JPM_TICKER: str = \"JPM\"\n",
    "\n",
    "aapl_stock_filename: str = f\"{AAPL_TICKER}.csv\"\n",
    "acwi_stock_filename: str = f\"{ACWI_TICKER}.csv\"\n",
    "jpm_stock_filename: str = f\"{JPM_TICKER}.csv\"\n",
    "\n",
    "aapl_df: pd.DataFrame = pd.read_csv(prod_data_folder.joinpath(aapl_stock_filename))\n",
    "acwi_df: pd.DataFrame = pd.read_csv(prod_data_folder.joinpath(acwi_stock_filename))\n",
    "jpm_df: pd.DataFrame = pd.read_csv(prod_data_folder.joinpath(jpm_stock_filename))\n",
    "\n",
    "aapl_df[\"Date\"] = pd.to_datetime(aapl_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "acwi_df[\"Date\"] = pd.to_datetime(acwi_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "jpm_df[\"Date\"] = pd.to_datetime(jpm_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "aapl_min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "acwi_min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "jpm_min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "aapl_min_max_scaler.fit(aapl_df[[\"Close\"]])\n",
    "acwi_min_max_scaler.fit(acwi_df[[\"Close\"]])\n",
    "jpm_min_max_scaler.fit(jpm_df[[\"Close\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length=60, n_features=1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 128\n",
    "        self.seq_length = seq_length\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, self.hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(self.hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, n_features), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.unsqueeze(1).repeat(1, self.seq_length, self.n_features)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.output_layer(lstm_out)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_features=1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        return self.classifier(last_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_generator_model_filename: str = (\n",
    "    f\"{GENERATOR_KEYWORD}_{MODEL_TYPE}_{AAPL_TICKER}.pth\"\n",
    ")\n",
    "aapl_discriminator_model_filename: str = (\n",
    "    f\"{DISCRIMINATOR_KEYWORD}_{MODEL_TYPE}_{AAPL_TICKER}.pth\"\n",
    ")\n",
    "\n",
    "aapl_generator = Generator(100)\n",
    "aapl_discriminator = Discriminator()\n",
    "\n",
    "aapl_generator.load_state_dict(\n",
    "    torch.load(model_artifact / aapl_generator_model_filename)\n",
    ")\n",
    "aapl_discriminator.load_state_dict(\n",
    "    torch.load(model_artifact / aapl_discriminator_model_filename)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "aapl_generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.randn(100, 1, 100)\n",
    "    for i in range(100):\n",
    "        output_tensor = aapl_generator(input_tensor[i])\n",
    "        ax.plot(\n",
    "            aapl_min_max_scaler.inverse_transform(output_tensor[0].numpy()),\n",
    "            label=f\"Sample {i}\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\"AAPL RNN Generator Model Architecture\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acwi_generator_model_filename: str = (\n",
    "    f\"{GENERATOR_KEYWORD}_{MODEL_TYPE}_{ACWI_TICKER}.pth\"\n",
    ")\n",
    "acwi_discriminator_model_filename: str = (\n",
    "    f\"{DISCRIMINATOR_KEYWORD}_{MODEL_TYPE}_{ACWI_TICKER}.pth\"\n",
    ")\n",
    "\n",
    "acwi_generator = Generator(100)\n",
    "acwi_discriminator = Discriminator()\n",
    "\n",
    "acwi_generator.load_state_dict(\n",
    "    torch.load(model_artifact / acwi_generator_model_filename)\n",
    ")\n",
    "acwi_discriminator.load_state_dict(\n",
    "    torch.load(model_artifact / acwi_discriminator_model_filename)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "acwi_generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.randn(100, 1, 100)\n",
    "    for i in range(100):\n",
    "        output_tensor = acwi_generator(input_tensor[i])\n",
    "        ax.plot(\n",
    "            acwi_min_max_scaler.inverse_transform(output_tensor[0].numpy()),\n",
    "            label=f\"Sample {i}\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\"ACWI RNN Generator Model Architecture\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_generator_model_filename: str = f\"{GENERATOR_KEYWORD}_{MODEL_TYPE}_{JPM_TICKER}.pth\"\n",
    "jpm_discriminator_model_filename: str = (\n",
    "    f\"{DISCRIMINATOR_KEYWORD}_{MODEL_TYPE}_{JPM_TICKER}.pth\"\n",
    ")\n",
    "\n",
    "jpm_generator = Generator(100)\n",
    "jpm_discriminator = Discriminator()\n",
    "\n",
    "jpm_generator.load_state_dict(torch.load(model_artifact / jpm_generator_model_filename))\n",
    "jpm_discriminator.load_state_dict(\n",
    "    torch.load(model_artifact / jpm_discriminator_model_filename)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "jpm_generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.randn(40, 1, 100)\n",
    "    for i in range(40):\n",
    "        output_tensor = jpm_generator(input_tensor[i])\n",
    "        ax.plot(\n",
    "            jpm_min_max_scaler.inverse_transform(output_tensor[0].numpy()),\n",
    "            label=f\"Sample {i}\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\"JPM RNN Generator Model Architecture\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SyntheticTimeSeries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
