@article{EckerliFlorian2021GANi,
  abstract = {Modelling in finance is a challenging task: the data often has complex
  statistical properties and its inner workings are largely unknown. Deep
  learning algorithms are making progress in the field of data-driven modelling,
  but the lack of sufficient data to train these models is currently holding back
  several new applications. Generative Adversarial Networks (GANs) are a neural
  network architecture family that has achieved good results in image generation
  and is being successfully applied to generate time series and other types of
  financial data. The purpose of this study is to present an overview of how
  these GANs work, their capabilities and limitations in the current state of
  research with financial data, and present some practical applications in the
  industry. As a proof of concept, three known GAN architectures were tested on
  financial time series, and the generated data was evaluated on its statistical
  properties, yielding solid results. Finally, it was shown that GANs have made
  considerable progress in their finance applications and can be a solid
  additional tool for data scientists in this field.},
  author = {Eckerli, Florian and Osterrieder, Joerg},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  language = {eng},
  title = {Generative Adversarial Networks in finance: an overview},
  year = {2021},
}

@article{GoodfellowIanJ2014GAN,
abstract = {We propose a new framework for estimating generative models via an
adversarial process, in which we simultaneously train two models: a generative
model G that captures the data distribution, and a discriminative model D that
estimates the probability that a sample came from the training data rather than
G. The training procedure for G is to maximize the probability of D making a
mistake. This framework corresponds to a minimax two-player game. In the space
of arbitrary functions G and D, a unique solution exists, with G recovering the
training data distribution and D equal to 1/2 everywhere. In the case where G
and D are defined by multilayer perceptrons, the entire system can be trained
with backpropagation. There is no need for any Markov chains or unrolled
approximate inference networks during either training or generation of samples.
Experiments demonstrate the potential of the framework through qualitative and
quantitative evaluation of the generated samples.},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
title = {Generative Adversarial Networks},
year = {2014},
}

