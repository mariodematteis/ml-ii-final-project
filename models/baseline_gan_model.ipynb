{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "production_data_path: Path = Path(\"../data/30_prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_market_dataset_name: str = \"ticker_data_final.csv\"\n",
    "df: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=production_data_path / \"ticker_data_final.csv\",\n",
    "    parse_dates=[\"Unnamed: 0\"],\n",
    "    sep=\",\",\n",
    ")\n",
    "df.rename(columns={\"Unnamed: 0\": \"Date\"}, inplace=True)\n",
    "assert pd.api.types.is_datetime64_any_dtype(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of days in the dataset: {df.shape[0]}\")\n",
    "print(f\"Starting date of the dataset: {df.index[0].strftime('%d %b %Y')}\")\n",
    "print(f\"Ending date of the dataset: {df.index[-1].strftime('%d %b %Y')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ticker_objective: str = \"AAPL.MX\"\n",
    "\n",
    "features_: NDArray[np.float64] = df[ticker_objective].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ticker_objective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "yf_ticker = yf.Ticker(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_ticker.history(period=\"1d\", start=\"2024-01-01\", end=\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context='talk', font_scale=0.7)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed: int = 42\n",
    "\n",
    "torch.manual_seed(manual_seed)\n",
    "np.random.seed(manual_seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def preprocess_financial_data(df, sequence_length=60):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        sequences.append(scaled_data[i : i + sequence_length])\n",
    "\n",
    "    return np.array(sequences), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 60\n",
    "sequences, scaler = preprocess_financial_data(features_.reshape(-1, 1), sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "real_data = torch.FloatTensor(sequences)\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "dataset = TimeSeriesDataset(real_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, n_features):\n",
    "        super(Generator, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, seq_length * n_features),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        output = self.model(z)\n",
    "        return output.view(-1, self.seq_length, self.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, seq_length, n_features):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(64 * seq_length, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.leaky_relu(output)\n",
    "        output = self.flatten(output)\n",
    "        output = self.linear(output)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "latent_dim = 100\n",
    "seq_length = 60\n",
    "n_features = 1\n",
    "lr = 0.0002\n",
    "epochs = 1000\n",
    "\n",
    "generator = Generator(latent_dim, seq_length, n_features).to(device)\n",
    "discriminator = Discriminator(seq_length, n_features).to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, real_samples in enumerate(dataloader):\n",
    "        real_samples = real_samples.to(device)\n",
    "        batch_size = real_samples.size(0)\n",
    "\n",
    "        valid = torch.ones(batch_size, 1, device=device)\n",
    "        fake = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        print(real_samples.shape)\n",
    "        discriminator(real_samples)\n",
    "\n",
    "        real_loss = criterion(discriminator(real_samples), valid)\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_samples = generator(z)\n",
    "        fake_loss = criterion(discriminator(fake_samples.detach()), fake)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        gen_samples = generator(z)\n",
    "        g_loss = criterion(discriminator(gen_samples), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch}/{epochs}] Loss D: {d_loss.item():.4f}, Loss G: {g_loss.item():.4f}\"\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_noise = torch.randn(1, latent_dim, device=device)\n",
    "\n",
    "            generated_sample = generator(test_noise)\n",
    "\n",
    "            generated_sample = generated_sample.cpu().numpy().squeeze()\n",
    "            real_sample = real_samples[0].cpu().numpy().squeeze()\n",
    "\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(generated_sample)\n",
    "            plt.title(\"Generated Sample\")\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(real_sample)\n",
    "            plt.title(\"Real Sample\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "\n",
    "    for _ in range(10):\n",
    "        z = torch.randn(1, latent_dim, device=device)\n",
    "        generated_sample = generator(z).flatten().cpu().numpy()\n",
    "        ax1.plot(generated_sample)\n",
    "        ax2.hist(generated_sample, bins=20, alpha=0.3)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_synthetic(synthetic_data, scaler):\n",
    "    \"\"\"\n",
    "    Convert generated data back to original price scale\n",
    "    \"\"\"\n",
    "    synthetic_np = synthetic_data.squeeze().cpu().numpy().reshape(-1, 1)\n",
    "    print(synthetic_np.shape)\n",
    "    return scaler.inverse_transform(synthetic_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1, latent_dim, device=device)\n",
    "    generated_sample = generator(z)\n",
    "    inverse_transform_synthetic(generated_sample, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator.pth\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(10, latent_dim, device=device)\n",
    "    synthetic_data = generator(noise).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.plot(synthetic_data[i].squeeze())\n",
    "    plt.title(f\"Synthetic Sample {i+1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "num_samples = 5\n",
    "z = torch.randn(num_samples, latent_dim)\n",
    "generated_sequences = generator(z).detach().numpy()\n",
    "\n",
    "# Inverse transform and plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(num_samples):\n",
    "    sequence = generated_sequences[i].reshape(-1, 1)\n",
    "    inv_sequence = scaler.inverse_transform(sequence)\n",
    "    plt.plot(inv_sequence, alpha=0.7, label=\"Synthetic\" if i == 0 else \"\")\n",
    "\n",
    "real_sample = scaler.inverse_transform(X[-1].numpy().reshape(-1, 1))\n",
    "plt.plot(real_sample, alpha=0.7, label=\"Real\")\n",
    "\n",
    "plt.title(\"Real vs. Synthetic Financial Time Series\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(10, latent_dim, device=device)\n",
    "    synthetic_data = generator(noise)\n",
    "\n",
    "synthetic_prices = inverse_transform_synthetic(synthetic_data, scaler)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.plot(synthetic_prices[i])\n",
    "    plt.title(f\"Synthetic Price Series {i+1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SyntheticTimeSeries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
